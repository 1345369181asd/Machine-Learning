## 1.多臂赌博机 {#1多臂赌博机}

 多臂赌博机是指一类问题，这类问题重复的从k个行为\(action\)中选择一个，并获得一个奖励\(reward\)，一次选择的时间周期称为一个时间步\(time-step\)。当选择并执行完一个行为后，得到一个奖励，我们称奖励的期望为这次行为的**真实值\(value\)**。在t时刻选择的行为用At表示，对应的奖励用Rt表示，对于行为a，其真实值为q∗\(a\),表示行为a的期望奖励，即：

$$q_*(a)=E[R_t|A_t=a]$$

 如果我们知道每个行为的真实值，那么多臂赌博机的问题很容易就可以解决，但在大多数情况下，我们是不知道行为的具体值的，因此只能做近似。在t时刻用$$Q_t(a)$$作为$$q_*(a)$$的**估计值**，即$$Q_t(a)$$约等于$$q_*(a)$$

   在时刻t，我们可以利用已有的知识即行为的估计值进行行为的最优选择，这种操作称为_exploit_，如果不选择当前的最优行为，我们称这种操作为_explore_，explore操作能够提高对行为值估计的准确度。exploit操作能够最大化当前步的奖励，但explore操作可能会使长期的奖励更大。如何平衡exploit操作和explore操作是强化学习中的一个重要问题。





