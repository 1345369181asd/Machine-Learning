在高维数据处理中，为了简化计算量以及储存空间，需要对这些高维数据进行一定程度上的降维，并尽量保证数据的不失真。PCA和ICA是两种常用的降维方法。

PCA：principal component analysis ，主成分分析

ICA ：Independent component analysis，独立成分分析

PCA,ICA都是统计理论当中的概念，在[机器学习](http://lib.csdn.net/base/machinelearning)当中应用很广，比如图像，语音，通信的分析处理。

从线性代数的角度去理解，PCA和ICA都是要找到一组基，这组基张成一个特征空间，数据的处理就都需要映射到新空间中去。

两者常用于机器学习中提取特征后的降维操作



ICA是找出构成信号的相互独立部分\(不需要正交\)，对应高阶统计量分析。ICA理论认为用来观测的混合数据阵X是由独立元S经过A线性加权获得。ICA理论的目标就是通过X求得一个分离矩阵W，使得W作用在X上所获得的信号Y是独立源S的最优逼近，该关系可以通过下式表示：

Y = WX = WAS ， A = inv\(W\)

ICA相比与PCA更能刻画变量的随机统计特性，且能抑制高斯噪声。

![](http://img.blog.csdn.net/20130511200133185)

