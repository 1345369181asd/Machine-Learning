## 目录 · · · · · ·

译者序 iv

  


序 vii

  


前言 ix

  


术语缩写 xxii

  


符号 xxvii

  


第 1 章 简介 1

  


1.1 自动语音识别：更好的沟通之桥 . . . . . . . . . . . . . . . . . . . . . . . 1

  


1.1.1 人类之间的交流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

  


1.1.2 人机交流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

  


1.2 语音识别系统的基本结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . 4

  


1.3 全书结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

  


1.3.1 第一部分：传统声学模型 . . . . . . . . . . . . . . . . . . . . . . 6

  


1.3.2 第二部分：深度神经网络 . . . . . . . . . . . . . . . . . . . . . . 6

  


1.3.3 第三部分：语音识别中的 DNN-HMM 混合系统 . . . . . . . . . . 7

  


1.3.4 第四部分：深度神经网络中的表征学习 . . . . . . . . . . . . . . 7

  


1.3.5 第五部分：高级的深度模型 . . . . . . . . . . . . . . . . . . . . . 7

  


第一部分 传统声学模型 9

  


第 2 章 混合高斯模型 11

  


2.1 随机变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

  


2.2 高斯分布和混合高斯随机变量 . . . . . . . . . . . . . . . . . . . . . . . . 12

  


2.3 参数估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

  


2.4 采用混合高斯分布对语音特征建模 . . . . . . . . . . . . . . . . . . . . . 16

  


第 3 章 隐马尔可夫模型及其变体 19

  


3.1 介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

  


3.2 马尔可夫链 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

  


3.3 序列与模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

  


3.3.1 隐马尔可夫模型的性质 . . . . . . . . . . . . . . . . . . . . . . . . 23

  


3.3.2 隐马尔可夫模型的仿真 . . . . . . . . . . . . . . . . . . . . . . . . 24

  


3.3.3 隐马尔可夫模型似然度的计算 . . . . . . . . . . . . . . . . . . . . 24

  


3.3.4 计算似然度的高效算法 . . . . . . . . . . . . . . . . . . . . . . . . 26

  


3.3.5 前向与后向递归式的证明 . . . . . . . . . . . . . . . . . . . . . . 27

  


3.4 期望最大化算法及其在学习 HMM 参数中的应用 . . . . . . . . . . . . . 28

  


3.4.1 期望最大化算法介绍 . . . . . . . . . . . . . . . . . . . . . . . . . 28

  


3.4.2 使用 EM 算法来学习 HMM 参数——Baum-Welch 算法 . . . . . . 30

  


3.5 用于解码 HMM 状态序列的维特比算法 . . . . . . . . . . . . . . . . . . . 34

  


3.5.1 动态规划和维特比算法 . . . . . . . . . . . . . . . . . . . . . . . . 34

  


3.5.2 用于解码 HMM 状态的动态规划算法 . . . . . . . . . . . . . . . . 35

  


3.6 隐马尔可夫模型和生成语音识别模型的变体 . . . . . . . . . . . . . . . . 37

  


3.6.1 用于语音识别的 GMM-HMM 模型 . . . . . . . . . . . . . . . . . 38

  


3.6.2 基于轨迹和隐藏动态模型的语音建模和识别 . . . . . . . . . . . . 39

  


3.6.3 使用生成模型 HMM 及其变体解决语音识别问题 . . . . . . . . . 40

  


第二部分 深度神经网络 43

  


第 4 章 深度神经网络 45

  


4.1 深度神经网络框架 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45

  


4.2 使用误差反向传播来进行参数训练 . . . . . . . . . . . . . . . . . . . . . 48

  


4.2.1 训练准则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

  


4.2.2 训练算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

  


4.3 实际应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53

  


4.3.1 数据预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54

  


4.3.2 模型初始化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55

  


4.3.3 权重衰减 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55

  


4.3.4 丢弃法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56

  


4.3.5 批量块大小的选择 . . . . . . . . . . . . . . . . . . . . . . . . . . 58

  


4.3.6 取样随机化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59

  


4.3.7 惯性系数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60

  


4.3.8 学习率和停止准则 . . . . . . . . . . . . . . . . . . . . . . . . . . 61

  


4.3.9 网络结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62

  


4.3.10 可复现性与可重启性 . . . . . . . . . . . . . . . . . . . . . . . . . 62

  


第 5 章 高级模型初始化技术 65

  


5.1 受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65

  


5.1.1 受限玻尔兹曼机的属性 . . . . . . . . . . . . . . . . . . . . . . . . 67

  


5.1.2 受限玻尔兹曼机参数学习 . . . . . . . . . . . . . . . . . . . . . . 70

  


5.2 深度置信网络预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73

  


5.3 降噪自动编码器预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76

  


5.4 鉴别性预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78

  


5.5 混合预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78

  


5.6 采用丢弃法的预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79

  


第三部分 语音识别中的深度神经网络–隐马尔可夫混合模型 81

  


第 6 章 深度神经网络–隐马尔可夫模型混合系统 83

  


6.1 DNN-HMM 混合系统 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83

  


6.1.1 结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83

  


6.1.2 用 CD-DNN-HMM 解码 . . . . . . . . . . . . . . . . . . . . . . . . 85

  


6.1.3 CD-DNN-HMM 训练过程 . . . . . . . . . . . . . . . . . . . . . . . 86

  


6.1.4 上下文窗口的影响 . . . . . . . . . . . . . . . . . . . . . . . . . . 88

  


6.2 CD-DNN-HMM 的关键模块及分析 . . . . . . . . . . . . . . . . . . . . . 90

  


6.2.1 进行比较和分析的数据集和实验 . . . . . . . . . . . . . . . . . . 90

  


6.2.2 对单音素或者三音素的状态进行建模 . . . . . . . . . . . . . . . . 92

  


6.2.3 越深越好 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93

  


6.2.4 利用相邻的语音帧 . . . . . . . . . . . . . . . . . . . . . . . . . . 94

  


6.2.5 预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95

  


6.2.6 训练数据的标注质量的影响 . . . . . . . . . . . . . . . . . . . . . 95

  


6.2.7 调整转移概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96

  


6.3 基于 KL 距离的隐马尔可夫模型 . . . . . . . . . . . . . . . . . . . . . . . 96

  


第 7 章 训练和解码的加速 99

  


7.1 训练加速 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99

  


7.1.1 使用多 GPU 流水线反向传播 . . . . . . . . . . . . . . . . . . . . 100

  


7.1.2 异步随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . 103

  


7.1.3 增广拉格朗日算法及乘子方向交替算法 . . . . . . . . . . . . . . 106

  


7.1.4 减小模型规模 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107

  


7.1.5 其他方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108

  


7.2 加速解码 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109

  


7.2.1 并行计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109

  


7.2.2 稀疏网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111

  


7.2.3 低秩近似 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113

  


7.2.4 用大尺寸 DNN 训练小尺寸 DNN . . . . . . . . . . . . . . . . . . 114

  


7.2.5 多帧 DNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115

  


第 8 章 深度神经网络序列鉴别性训练 117

  


8.1 序列鉴别性训练准则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117

  


8.1.1 最大相互信息 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118

  


8.1.2 增强型 MMI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119

  


8.1.3 最小音素错误/状态级最小贝叶斯风险 . . . . . . . . . . . . . . . 120

  


8.1.4 统一的公式 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121

  


8.2 具体实现中的考量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122

  


8.2.1 词图产生 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122

  


8.2.2 词图补偿 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123

  


8.2.3 帧平滑 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125

  


8.2.4 学习率调整 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125

  


8.2.5 训练准则选择 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126

  


8.2.6 其他考量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126

  


8.3 噪声对比估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127

  


8.3.1 将概率密度估计问题转换为二分类设计问题 . . . . . . . . . . . . 127

  


8.3.2 拓展到未归一化的模型 . . . . . . . . . . . . . . . . . . . . . . . . 129

  


8.3.3 在深度学习网络训练中应用噪声对比估计算法 . . . . . . . . . . 130

  


第四部分 深度神经网络中的特征表示学习 133

  


第 9 章 深度神经网络中的特征表示学习 135

  


9.1 特征和分类器的联合学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . 135

  


9.2 特征层级 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136

  


9.3 使用随意输入特征的灵活性 . . . . . . . . . . . . . . . . . . . . . . . . . 140

  


9.4 特征的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141

  


9.4.1 对说话人变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . 141

  


9.4.2 对环境变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . 142

  


9.5 对环境的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144

  


9.5.1 对噪声的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145

  


9.5.2 对语速变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . 147

  


9.6 缺乏严重信号失真情况下的推广能力 . . . . . . . . . . . . . . . . . . . . 148

  


第 10 章 深度神经网络和混合高斯模型的融合 151

  


10.1 在 GMM-HMM 系统中使用由 DNN 衍生的特征 . . . . . . . . . . . . . . 151

  


10.1.1 使用 Tandem 和瓶颈特征的 GMM-HMM 模型 . . . . . . . . . . . 151

  


10.1.2 DNN-HMM 混合系统与采用深度特征的 GMM-HMM 系统的比较 154

  


10.2 识别结果融合技术 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156

  


10.2.1 识别错误票选降低技术（ ROVER） . . . . . . . . . . . . . . . . . 157

  


10.2.2 分段条件随机场（ SCARF） . . . . . . . . . . . . . . . . . . . . . 159

  


10.2.3 最小贝叶斯风险词图融合 . . . . . . . . . . . . . . . . . . . . . . 160

  


10.3 帧级别的声学分数融合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160

  


10.4 多流语音识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161

  


第 11 章 深度神经网络的自适应技术 165

  


11.1 深度神经网络中的自适应问题 . . . . . . . . . . . . . . . . . . . . . . . . 165

  


11.2 线性变换 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167

  


11.2.1 线性输入网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167

  


11.2.2 线性输出网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167

  


11.3 线性隐层网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169

  


11.4 保守训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170

  


11.4.1 L 2 正则项 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171

  


11.4.2 KL 距离正则项 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171

  


11.4.3 减少每个说话人的模型开销 . . . . . . . . . . . . . . . . . . . . . 173

  


11.5 子空间方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175

  


11.5.1 通过主成分分析构建子空间 . . . . . . . . . . . . . . . . . . . . . 175

  


11.5.2 噪声感知、说话人感知及设备感知训练 . . . . . . . . . . . . . . 176

  


11.5.3 张量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180

  


11.6 DNN 说话人自适应的效果 . . . . . . . . . . . . . . . . . . . . . . . . . . 181

  


11.6.1 基于 KL 距离的正则化方法 . . . . . . . . . . . . . . . . . . . . . 181

  


11.6.2 说话人感知训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183

  


第五部分 先进的深度学习模型 185

  


第 12 章 深度神经网络中的表征共享和迁移 187

  


12.1 多任务和迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187

  


12.1.1 多任务学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187

  


12.1.2 迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189

  


12.2 多语言和跨语言语音识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . 189

  


12.2.1 基于 Tandem 或瓶颈特征的跨语言语音识别 . . . . . . . . . . . . 190

  


12.2.2 共享隐层的多语言深度神经网络 . . . . . . . . . . . . . . . . . . 191

  


12.2.3 跨语言模型迁移 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194

  


12.3 语音识别中深度神经网络的多目标学习 . . . . . . . . . . . . . . . . . . . 197

  


12.3.1 使用多任务学习的鲁棒语音识别 . . . . . . . . . . . . . . . . . . 197

  


12.3.2 使用多任务学习改善音素识别 . . . . . . . . . . . . . . . . . . . . 198

  


12.3.3 同时识别音素和字素（ graphemes） . . . . . . . . . . . . . . . . . 199

  


12.4 使用视听信息的鲁棒语音识别 . . . . . . . . . . . . . . . . . . . . . . . . 199

  


第 13 章 循环神经网络及相关模型 201

  


13.1 介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201

  


13.2 基本循环神经网络中的状态-空间公式 . . . . . . . . . . . . . . . . . . . . 203

  


13.3 沿时反向传播学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204

  


13.3.1 最小化目标函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205

  


13.3.2 误差项的递归计算 . . . . . . . . . . . . . . . . . . . . . . . . . . 205

  


13.3.3 循环神经网络权重的更新 . . . . . . . . . . . . . . . . . . . . . . 206

  


13.4 一种用于学习循环神经网络的原始对偶技术 . . . . . . . . . . . . . . . . 208

  


13.4.1 循环神经网络学习的难点 . . . . . . . . . . . . . . . . . . . . . . 208

  


13.4.2 回声状态（ Echo-State）性质及其充分条件 . . . . . . . . . . . . . 208

  


13.4.3 将循环神经网络的学习转化为带约束的优化问题 . . . . . . . . . 209

  


13.4.4 一种用于学习 RNN 的原始对偶方法 . . . . . . . . . . . . . . . . 210

  


13.5 结合长短时记忆单元（ LSTM）的循环神经网络 . . . . . . . . . . . . . . 212

  


13.5.1 动机与应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212

  


13.5.2 长短时记忆单元的神经元架构 . . . . . . . . . . . . . . . . . . . . 213

  


13.5.3 LSTM-RNN 的训练 . . . . . . . . . . . . . . . . . . . . . . . . . . 214

  


13.6 循环神经网络的对比分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . 214

  


13.6.1 信息流方向的对比：自上而下还是自下而上 . . . . . . . . . . . . 215

  


13.6.2 信息表征的对比：集中式还是分布式 . . . . . . . . . . . . . . . . 217

  


13.6.3 解释能力的对比：隐含层推断还是端到端学习 . . . . . . . . . . 218

  


13.6.4 参数化方式的对比：吝啬参数集合还是大规模参数矩阵 . . . . . 218

  


13.6.5 模型学习方法的对比：变分推理还是梯度下降 . . . . . . . . . . 219

  


13.6.6 识别正确率的比较 . . . . . . . . . . . . . . . . . . . . . . . . . . 220

  


13.7 讨论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221

  


第 14 章 计算型网络 223

  


14.1 计算型网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223

  


14.2 前向计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224

  


14.3 模型训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227

  


14.4 典型的计算节点 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231

  


14.4.1 无操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . . . . 232

  


14.4.2 含一个操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . 232

  


14.4.3 含两个操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . 237

  


14.4.4 用来计算统计量的计算节点类型 . . . . . . . . . . . . . . . . . . 244

  


14.5 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245

  


14.6 循环连接 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248

  


14.6.1 只在循环中一个接一个地处理样本 . . . . . . . . . . . . . . . . . 249

  


14.6.2 同时处理多个句子 . . . . . . . . . . . . . . . . . . . . . . . . . . 251

  


14.6.3 创建任意的循环神经网络 . . . . . . . . . . . . . . . . . . . . . . 252

  


第 15 章 总结及未来研究方向 255

  


15.1 路线图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255

  


15.1.1 语音识别中的深度神经网络启蒙 . . . . . . . . . . . . . . . . . . 255

  


15.1.2 深度神经网络训练和解码加速 . . . . . . . . . . . . . . . . . . . . 258

  


15.1.3 序列鉴别性训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258

  


15.1.4 特征处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259

  


15.1.5 自适应 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260

  


15.1.6 多任务和迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 261

  


15.1.7 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261

  


15.1.8 循环神经网络和长短时记忆神经网络 . . . . . . . . . . . . . . . . 261

  


15.1.9 其他深度模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262

  


15.2 技术前沿和未来方向 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262

  


15.2.1 技术前沿简析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262

  


15.2.2 未来方向 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263

  


参考文献 267

