经常地，对一堆数据进行建模的时候，特别是分类和回归模型，我们有很多的变量可供使用，选择不同的变量组合可以得到不同的模型，例如我们有5个变量，2的5次方，我们将有32个变量组合，可以训练出32个模型。但是哪个模型更加的好呢？目前常用有如下方法：

AIC=-2 ln\(L\) + 2 k  中文名字：赤池信息量 akaike information criterion

BIC=-2 ln\(L\) + ln\(n\)\*k 中文名字：贝叶斯信息量 bayesian information criterion

HQ=-2 ln\(L\) + ln\(ln\(n\)\)\*k  hannan-quinn criterion

其中L是在该模型下的最大似然，n是数据数量，k是模型的变量个数。

选择最优模型的指导思想是从两个方面去考察：一个是似然函数最大化，另一个是模型中的未知参数个数最小化。似然函数值越大说明模型拟合的效果越好，但是我们不能单纯地以拟合精度来衡量模型的优劣，这样回导致模型中未知参数越来越多，模型变得越来越复杂，会造成过拟合。所以一个好的模型应该是拟合精度和未知参数个数的综合最优化配置。



注意这些规则只是刻画了用某个模型之后相对“真实模型”的信息损失【因为不知道真正的模型是什么样子，所以训练得到的所有模型都只是真实模型的一个近似模型】，所以用这些规则不能说明某个模型的精确度，即三个模型A, B, C，在通过这些规则计算后，我们知道B模型是三个模型中最好的，但是不能保证B这个模型就能够很好地刻画数据，因为很有可能这三个模型都是非常糟糕的，B只是烂苹果中的相对好的苹果而已。

这些规则理论上是比较漂亮的，但是实际在模型选择中应用起来还是有些困难的，例如上面我们说了5个变量就有32个变量组合，如果是10个变量呢？2的10次方，我们不可能对所有这些模型进行一一验证AIC, BIC，HQ规则来选择模型，工作量太大。



